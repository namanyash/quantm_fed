{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LnABu8DQ22Gj",
        "outputId": "306bc6c0-c25d-47a3-f0fc-256de49bea0c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\r0% [Working]\r            \rHit:1 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "\r0% [Waiting for headers] [Waiting for headers] [Waiting for headers] [Connectin\r                                                                               \rGet:2 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [119 kB]\n",
            "\r0% [2 InRelease 12.7 kB/119 kB 11%] [Waiting for headers] [Waiting for headers]\r                                                                               \rGet:3 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\n",
            "\r0% [2 InRelease 12.7 kB/119 kB 11%] [Waiting for headers] [3 InRelease 0 B/3,62\r0% [2 InRelease 15.6 kB/119 kB 13%] [Waiting for headers] [Connected to ppa.lau\r                                                                               \rHit:4 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Get:5 http://security.ubuntu.com/ubuntu jammy-security InRelease [110 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [109 kB]\n",
            "Get:7 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy InRelease [18.1 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,236 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu jammy-updates/multiverse amd64 Packages [49.8 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [1,129 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [918 kB]\n",
            "Hit:12 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Get:13 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [979 kB]\n",
            "Get:14 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease [24.3 kB]\n",
            "Get:15 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [857 kB]\n",
            "Get:16 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [832 kB]\n",
            "Hit:17 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:18 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy/main Sources [2,165 kB]\n",
            "Get:19 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy/main amd64 Packages [1,112 kB]\n",
            "Get:20 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy/main amd64 Packages [36.0 kB]\n",
            "Fetched 9,697 kB in 4s (2,242 kB/s)\n",
            "Reading package lists... Done\n"
          ]
        }
      ],
      "source": [
        "!sudo apt-get update -y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j3lsGWT920SW",
        "outputId": "6ae8e1e5-3a78-43e5-b8c1-43f5d822b881"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "update-alternatives: error: no alternatives for python3\n"
          ]
        }
      ],
      "source": [
        "# select python version\n",
        "!sudo update-alternatives --config python3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x9VWKKyW2y6P",
        "outputId": "f346c108-b015-4d2d-9380-7f8a9cba6a2e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Python 3.10.12\n"
          ]
        }
      ],
      "source": [
        "# check python version\n",
        "!python --version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KOt6rd922w4O",
        "outputId": "d988b111-c45f-4000-9f10-2d0d777e04b5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  python3.8-lib2to3\n",
            "The following NEW packages will be installed:\n",
            "  python3.8-distutils python3.8-lib2to3\n",
            "0 upgraded, 2 newly installed, 0 to remove and 23 not upgraded.\n",
            "Need to get 319 kB of archives.\n",
            "After this operation, 1,237 kB of additional disk space will be used.\n",
            "Get:1 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 python3.8-lib2to3 all 3.8.17-1+jammy1 [126 kB]\n",
            "Get:2 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 python3.8-distutils all 3.8.17-1+jammy1 [193 kB]\n",
            "Fetched 319 kB in 1s (218 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 2.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package python3.8-lib2to3.\n",
            "(Reading database ... 120828 files and directories currently installed.)\n",
            "Preparing to unpack .../python3.8-lib2to3_3.8.17-1+jammy1_all.deb ...\n",
            "Unpacking python3.8-lib2to3 (3.8.17-1+jammy1) ...\n",
            "Selecting previously unselected package python3.8-distutils.\n",
            "Preparing to unpack .../python3.8-distutils_3.8.17-1+jammy1_all.deb ...\n",
            "Unpacking python3.8-distutils (3.8.17-1+jammy1) ...\n",
            "Setting up python3.8-lib2to3 (3.8.17-1+jammy1) ...\n",
            "Setting up python3.8-distutils (3.8.17-1+jammy1) ...\n",
            "--2023-08-15 01:42:19--  https://bootstrap.pypa.io/get-pip.py\n",
            "Resolving bootstrap.pypa.io (bootstrap.pypa.io)... 151.101.0.175, 151.101.64.175, 151.101.128.175, ...\n",
            "Connecting to bootstrap.pypa.io (bootstrap.pypa.io)|151.101.0.175|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2605506 (2.5M) [text/x-python]\n",
            "Saving to: ‘get-pip.py’\n",
            "\n",
            "get-pip.py          100%[===================>]   2.48M  --.-KB/s    in 0.08s   \n",
            "\n",
            "2023-08-15 01:42:19 (31.7 MB/s) - ‘get-pip.py’ saved [2605506/2605506]\n",
            "\n",
            "Collecting pip\n",
            "  Obtaining dependency information for pip from https://files.pythonhosted.org/packages/50/c2/e06851e8cc28dcad7c155f4753da8833ac06a5c704c109313b8d5a62968a/pip-23.2.1-py3-none-any.whl.metadata\n",
            "  Downloading pip-23.2.1-py3-none-any.whl.metadata (4.2 kB)\n",
            "Downloading pip-23.2.1-py3-none-any.whl (2.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pip\n",
            "  Attempting uninstall: pip\n",
            "    Found existing installation: pip 23.1.2\n",
            "    Uninstalling pip-23.1.2:\n",
            "      Successfully uninstalled pip-23.1.2\n",
            "Successfully installed pip-23.2.1\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "# install pip for new python\n",
        "!sudo apt-get install python3.8-distutils\n",
        "!wget https://bootstrap.pypa.io/get-pip.py\n",
        "!python get-pip.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vIN_d4Hg2vB7",
        "outputId": "13974ee0-1a16-434e-9309-02e4e5e30cce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  python3-setuptools python3-wheel\n",
            "Suggested packages:\n",
            "  python-setuptools-doc\n",
            "The following NEW packages will be installed:\n",
            "  python3-pip python3-setuptools python3-wheel\n",
            "0 upgraded, 3 newly installed, 0 to remove and 23 not upgraded.\n",
            "Need to get 1,677 kB of archives.\n",
            "After this operation, 8,965 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 python3-setuptools all 59.6.0-1.2ubuntu0.22.04.1 [339 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 python3-wheel all 0.37.1-2ubuntu0.22.04.1 [32.0 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 python3-pip all 22.0.2+dfsg-1ubuntu0.3 [1,305 kB]\n",
            "Fetched 1,677 kB in 0s (4,889 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 3.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package python3-setuptools.\n",
            "(Reading database ... 120969 files and directories currently installed.)\n",
            "Preparing to unpack .../python3-setuptools_59.6.0-1.2ubuntu0.22.04.1_all.deb ...\n",
            "Unpacking python3-setuptools (59.6.0-1.2ubuntu0.22.04.1) ...\n",
            "Selecting previously unselected package python3-wheel.\n",
            "Preparing to unpack .../python3-wheel_0.37.1-2ubuntu0.22.04.1_all.deb ...\n",
            "Unpacking python3-wheel (0.37.1-2ubuntu0.22.04.1) ...\n",
            "Selecting previously unselected package python3-pip.\n",
            "Preparing to unpack .../python3-pip_22.0.2+dfsg-1ubuntu0.3_all.deb ...\n",
            "Unpacking python3-pip (22.0.2+dfsg-1ubuntu0.3) ...\n",
            "Setting up python3-setuptools (59.6.0-1.2ubuntu0.22.04.1) ...\n",
            "Setting up python3-wheel (0.37.1-2ubuntu0.22.04.1) ...\n",
            "Setting up python3-pip (22.0.2+dfsg-1ubuntu0.3) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n"
          ]
        }
      ],
      "source": [
        "!sudo apt install python3-pip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f9H8eWVT2tDq",
        "outputId": "ee0e1087-685b-4ffb-bf4a-489909d54947"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pip in /usr/local/lib/python3.10/dist-packages (23.2.1)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!python -m pip install --upgrade pip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PyS4U8sE1rrT",
        "outputId": "eafd7dd2-eb7d-48e4-b82d-64e02ebec303"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.12.0)\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement tensorflow-quantum==0.7.2 (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for tensorflow-quantum==0.7.2\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow tensorflow-quantum==0.7.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 420
        },
        "id": "yNI4k1O8H03V",
        "outputId": "5ac4c7c6-29f4-4231-97ff-7f0df8096277"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[31mERROR: Could not find a version that satisfies the requirement tensorflow_quantum (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for tensorflow_quantum\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        },
        {
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-35-33114d597bcc>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow_quantum\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtfq\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow_quantum'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import tensorflow_quantum as tfq\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tqdm import tqdm\n",
        "import math\n",
        "import mpmath\n",
        "import numpy as np\n",
        "import cirq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3AnJtbRUG0k0"
      },
      "outputs": [],
      "source": [
        "n_world = 10\n",
        "\n",
        "n=8\n",
        "dataset = 'mnist'\n",
        "readout_mode = 'softmax'\n",
        "encoding_mode = 'vanilla'\n",
        "n_node = 8\n",
        "k = 48\n",
        "\n",
        "simulator = cirq.Simulator()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6TS2gO2cHUi-"
      },
      "outputs": [],
      "source": [
        "print(\"Start\")\n",
        "if dataset == 'mnist':\n",
        "    (x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "elif dataset == 'fashion':\n",
        "    (x_train, y_train), (x_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()\n",
        "ind = y_test == 9\n",
        "x_test, y_test = x_test[~ind], y_test[~ind]\n",
        "ind = y_test == 8\n",
        "x_test, y_test = x_test[~ind], y_test[~ind]\n",
        "ind = y_train == 9\n",
        "x_train, y_train = x_train[~ind], y_train[~ind]\n",
        "ind = y_train == 8\n",
        "x_train, y_train = x_train[~ind], y_train[~ind]\n",
        "\n",
        "##### x_test (8017, 28, 28) uint8\n",
        "##### x_train (48200, 28, 28) uint8\n",
        "##### y_test (8017,) uint8\n",
        "##### y_train (48200,) uint8\n",
        "##### ind (54051) bool\n",
        "\n",
        "x_train = x_train / 255.0\n",
        "if encoding_mode == 'vanilla':\n",
        "    mean = 0\n",
        "elif encoding_mode == 'mean':\n",
        "    mean = np.mean(x_train, axis=0)\n",
        "elif encoding_mode == 'half':\n",
        "    mean = 0.5\n",
        "x_train = x_train - mean\n",
        "x_train = tf.image.resize(x_train[..., tf.newaxis], (int(2**(n/2)), int(2**(n/2)))).numpy()[..., 0].reshape(-1, 2**n)\n",
        "x_train = x_train / np.sqrt(np.sum(x_train**2, axis=-1, keepdims=True))\n",
        "\n",
        "x_test = x_test / 255.0\n",
        "x_test = x_test - mean\n",
        "x_test = tf.image.resize(x_test[..., tf.newaxis], (int(2**(n/2)), int(2**(n/2)))).numpy()[..., 0].reshape(-1, 2**n)\n",
        "x_test = x_test / np.sqrt(np.sum(x_test**2, axis=-1, keepdims=True))\n",
        "y_test = np.eye(n_node)[y_test]\n",
        "\n",
        "##### x_test (8017, 256) float32\n",
        "##### x_train (48200, 256) float32\n",
        "##### y_train (48200,) uint8\n",
        "##### ind (54051) bool\n",
        "##### y_test (8017,8) float64\n",
        "\n",
        "print(\"Processing 1 complete\")\n",
        "\n",
        "def filter_pair(x, y, a, b):\n",
        "    keep = (y == a) | (y == b)\n",
        "    x, y = x[keep], y[keep]\n",
        "    y = np.eye(n_node)[y]\n",
        "    return x, y\n",
        "\n",
        "params_list = []\n",
        "opt_state_list = []\n",
        "data_list = []\n",
        "iter_list = []\n",
        "for node in range(n_node-1):\n",
        "    x_train_node, y_train_node = filter_pair(x_train, y_train, 0, node + 1)\n",
        "    data = tf.data.Dataset.from_tensor_slices((x_train_node, y_train_node)).batch(128)\n",
        "    data_list.append(data)\n",
        "    iter_list.append(iter(data))\n",
        "\n",
        "    rng = np.random.default_rng(42)\n",
        "    key1, key2 = rng.integers(0, 2**31, size=2)\n",
        "\n",
        "    # Generate random numbers using NumPy\n",
        "    subkey, _ = np.random.default_rng(key2).integers(0, 2**31, size=2)\n",
        "    params = np.random.default_rng(subkey).normal(size=(3 * k, n))\n",
        "    params_list.append(params)\n",
        "\n",
        "\n",
        "##### x_test (8017, 256) float32\n",
        "##### x_train (48200, 256) float32\n",
        "##### y_test (8017, 8) float64\n",
        "##### y_train (48200,) uint8\n",
        "##### ind (54051) bool\n",
        "##### x_train_node (12188, 256) float32\n",
        "##### y_train_node (12188, 8) float64\n",
        "##### data (size 96) (python.data.ops.batch_op._BatchDataset)\n",
        "##### data_list (size 7)\n",
        "##### iter_list (size 7) OwnerIterator Iterator of data\n",
        "##### params (144, 8) Array of float64\n",
        "##### params_list size 7\n",
        "##### opt = GradientTransformationExtraArgs size 2\n",
        "##### opt_state tuple size 2\n",
        "##### opt_state_list (size 7)\n",
        "\n",
        "print (\"Processing done\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r5nnbi-_HbDF"
      },
      "outputs": [],
      "source": [
        "def norm(x: np.ndarray) -> np.ndarray:\n",
        "    mpmath.mp.dps = 50\n",
        "\n",
        "    # Convert numpy array to mpmath matrix\n",
        "    mp_matrix = mpmath.matrix(x.tolist())\n",
        "\n",
        "    # Normalize the vector using mpmath arithmetic\n",
        "    norm_factor = mpmath.norm(mp_matrix, 2)  # L2 norm\n",
        "    normalized_mp_matrix = mp_matrix / norm_factor\n",
        "\n",
        "    # Convert the mpmath matrix back to numpy array\n",
        "    normalized_x = np.array([float(entry) for row in normalized_mp_matrix.tolist() for entry in row]).ravel()\n",
        "\n",
        "    return normalized_x\n",
        "\n",
        "## Functions\n",
        "def clf(params, x, k):\n",
        "    qubits = [cirq.GridQubit(i, 0) for i in range(n)]\n",
        "    circuit = cirq.Circuit()\n",
        "\n",
        "\n",
        "    for j in range(k):\n",
        "        for i in range(n - 1):\n",
        "            circuit.append(cirq.CNOT(qubits[i], qubits[i + 1]))\n",
        "        for i in range(n):\n",
        "            circuit.append(cirq.rx(params[3 * j, i])(qubits[i]))\n",
        "            circuit.append(cirq.rz(params[3 * j + 1, i])(qubits[i]))\n",
        "            circuit.append(cirq.rx(params[3 * j + 2, i])(qubits[i]))\n",
        "\n",
        "\n",
        "    return circuit\n",
        "\"\"\"\n",
        "def readout(qc, x, readout_mode='softmax', shots=4000):\n",
        "    state_vector = cirq.final_state_vector(qc, initial_state=norm(x))\n",
        "    logits = []\n",
        "    for i in qc.all_qubits():\n",
        "        z_observable = cirq.Z(i)\n",
        "        expectation_z = z_observable.expectation_from_state_vector(state_vector, qubit_map={i: pos for pos, i in enumerate(qc.all_qubits())})\n",
        "        logits.append(expectation_z)\n",
        "\n",
        "    logits = np.array(logits) * 10  # scaling by 10 as in your example\n",
        "    probs = np.exp(logits) / sum(np.exp(logits))\n",
        "    return probs\n",
        "\n",
        "\n",
        "\n",
        "def loss(params, x, y, k):\n",
        "    c = clf(params, x, k)\n",
        "    probs = readout(c, x)\n",
        "    loss   = -np.mean(np.sum(y * np.log(probs + 1e-7), axis=-1))\n",
        "    return loss\n",
        "\"\"\"\n",
        "def readout(qc, x, readout_mode='softmax', shots=4000):\n",
        "    # Use TFQ for getting the expectation values\n",
        "    qubits = list(qc.all_qubits())\n",
        "    z_observables = [cirq.Z(q) for q in qubits]\n",
        "    expectation_layer = tfq.layers.Expectation()\n",
        "    expectations = expectation_layer([qc], operators=z_observables, initial_state=norm(x))\n",
        "\n",
        "    logits = tf.multiply(expectations, 10)\n",
        "    probs = tf.math.exp(logits) / tf.reduce_sum(tf.math.exp(logits))\n",
        "    return probs\n",
        "\n",
        "def loss(params, x, y, k):\n",
        "    c = clf(params, x, k)\n",
        "    probs = readout(c, x)\n",
        "    loss_value = -tf.reduce_mean(tf.reduce_sum(y * tf.math.log(probs + 1e-7), axis=-1))\n",
        "    return loss_value\n",
        "\n",
        "min_loss_so_far = 9999\n",
        "iteration = 0\n",
        "def run_circuit(params, x, y, k):\n",
        "    global iteration\n",
        "    global min_loss_so_far\n",
        "    total_loss = 0\n",
        "    new_params = params_tensor.numpy()\n",
        "    for index in range(x.shape[0]):\n",
        "        total_loss += loss(new_params, x[index], y[index], k)\n",
        "    mean_loss = total_loss/x.shape[0]\n",
        "    iteration += 1\n",
        "    print(iteration)\n",
        "    print(\"mean_loss\")\n",
        "    print(abs(mean_loss))\n",
        "    if(min_loss_so_far > mean_loss):\n",
        "      min_loss_so_far = mean_loss\n",
        "    if(iteration % 10 == 0 ):\n",
        "      print(min_loss_so_far)\n",
        "    return tf.convert_to_tensor(abs(mean_loss))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bpeUAelHHm1p"
      },
      "outputs": [],
      "source": [
        "loss_list = []\n",
        "acc_list = []\n",
        "for e in tqdm(range(5), leave=False):\n",
        "    for b in range(100):\n",
        "        for node in range(n_node-1):\n",
        "            try:\n",
        "                x, y = next(iter_list[node])\n",
        "            except StopIteration:\n",
        "                iter_list[node] = iter(data_list[node])\n",
        "                x, y = next(iter_list[node])\n",
        "            x = x.numpy()\n",
        "            y = y.numpy()\n",
        "            print(\"\\n\\nShape of X array:\", x.shape)\n",
        "            print(\"Shape of Y array:\", y.shape)\n",
        "\n",
        "            #a = x.reshape(-1)\n",
        "            #b = a.reshape(128,256)\n",
        "            params_tensor = tf.Variable(params_list[node], dtype=tf.float32)\n",
        "            optimizer = tf.optimizers.Adam(learning_rate=1e-2)\n",
        "\n",
        "            with tf.GradientTape() as tape:\n",
        "                current_loss = run_circuit(params_tensor, x, y, k)\n",
        "            gradients = tape.gradient(current_loss, [params_tensor])\n",
        "            optimizer.apply_gradients(zip(gradients, [params_tensor]))\n",
        "\n",
        "            # Extract the optimized parameters after training\n",
        "            params_list[node] = params_tensor.numpy()\n",
        "\n",
        "            print(f\"Epoch {e}, batch {b}/{100}, Node {node}\")\n",
        "            print((\"\\n\"))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
